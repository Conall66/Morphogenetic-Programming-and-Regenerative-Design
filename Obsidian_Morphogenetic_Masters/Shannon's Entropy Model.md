Quantifies the uncertainty or randomness in a source of information, providing a measure of the information content or "entropy" associated with a probability distribution

$H(X)=−i=1∑n​P(x_i​)log_b​P(x_i​)$

- Where $H(X)$ is the average uncertainty or "entropy" of the random variable X
- $P(X)$ is the average uncertainty of variable X
- 


